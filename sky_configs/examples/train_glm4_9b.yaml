name: slime-glm4-9b

resources:
  cloud: aws
  accelerators: H100:8
  use_spot: false

num_nodes: 1

file_mounts:
  /slime_checkpoints:
    name: slime-glm4-checkpoints
    store: s3
    mode: MOUNT

envs:
  PYTHONPATH: /root/Megatron-LM/
  CUDA_DEVICE_MAX_CONNECTIONS: "1"
  HF_MODEL_ID: zai-org/GLM-Z1-9B-0414
  MODEL_DIR: /root/GLM-Z1-9B-0414
  
setup: |
  set -ex
  
  cd /root
  if [ ! -d "slime" ]; then
    git clone https://github.com/THUDM/slime.git
  else
    cd slime && git pull && cd ..
  fi
  cd slime
  pip install -e .
  
  if [ ! -d "/root/Megatron-LM" ]; then
    git clone https://github.com/NVIDIA/Megatron-LM.git /root/Megatron-LM
  fi
  
  pip install -U huggingface_hub
  huggingface-cli download zai-org/GLM-Z1-9B-0414 --local-dir /root/GLM-Z1-9B-0414 || true
  huggingface-cli download --repo-type dataset zhuzilin/dapo-math-17k --local-dir /root/dapo-math-17k || true
  huggingface-cli download --repo-type dataset zhuzilin/aime-2024 --local-dir /root/aime-2024 || true
  
run: |
  set -ex
  
  cd /root/slime
  source scripts/models/glm4-9B.sh
  
  python train.py \
    --actor-num-nodes 1 \
    --actor-num-gpus-per-node 4 \
    --rollout-num-gpus 4 \
    --hf-checkpoint /root/GLM-Z1-9B-0414/ \
    --ref-load /slime_checkpoints/GLM-Z1-9B-0414_torch_dist \
    --load /slime_checkpoints/GLM-Z1-9B-0414_slime/ \
    --save /slime_checkpoints/GLM-Z1-9B-0414_slime/ \
    --save-interval 20 \
    --prompt-data /root/dapo-math-17k/dapo-math-17k.jsonl \
    --input-key prompt \
    --label-key label \
    --apply-chat-template \
    --rollout-shuffle \
    --rm-type deepscaler \
    --num-rollout 3000 \
    --rollout-batch-size 32 \
    --n-samples-per-prompt 8 \
    --rollout-max-response-len 8192 \
    --rollout-temperature 0.8 \
    --global-batch-size 256 \
    --balance-data \
    --eval-interval 20 \
    --eval-prompt-data aime /root/aime-2024/aime-2024.jsonl \
    --n-samples-per-eval-prompt 16 \
    --eval-max-response-len 16384 \
    --eval-top-p 0.7 \
    --tensor-model-parallel-size 2 \
    --sequence-parallel \
    --pipeline-model-parallel-size 1 \
    --context-parallel-size 2 \
    --expert-model-parallel-size 1 \
    --expert-tensor-parallel-size 1 \
    --recompute-granularity full \
    --recompute-method uniform \
    --recompute-num-layers 1 \
    --use-dynamic-batch-size \
    --max-tokens-per-gpu 4608 \
    --rollout-num-gpus-per-engine 2 \
    ${MODEL_ARGS[@]}
